"""
AIæ¨¡å‹ç®¡ç†æœåŠ¡
ç»Ÿä¸€ç®¡ç†å’Œåè°ƒæ‰€æœ‰AIæ¨¡å‹å®ä¾‹ - ä¿®å¤ç‰ˆ
"""
import asyncio
import os
from typing import Dict, Any, Optional, List, Union
from datetime import datetime
import numpy as np

# åœ¨å¯¼å…¥ä»»ä½•AIæ¨¡å‹åº“ä¹‹å‰ï¼Œé…ç½®ç¯å¢ƒå˜é‡ä»¥æŠ‘åˆ¶æ—¥å¿—è­¦å‘Š
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # TensorFlowæ—¥å¿—çº§åˆ«
os.environ['GRPC_VERBOSITY'] = 'ERROR'    # gRPCæ—¥å¿—çº§åˆ«
os.environ['GLOG_minloglevel'] = '2'      # Googleæ—¥å¿—æœ€å°çº§åˆ«
os.environ['GLOG_v'] = '0'               # Googleæ—¥å¿—è¯¦ç»†ç¨‹åº¦

from app.core.logging_config import logger

from app.services.ai_model_base import BaseAIModel, ModelType, ProviderType, ModelStatus, ModelManager, AIModelException
from app.utils.enum_helpers import get_enum_value
from app.core.config import get_settings
from app.services.bge_embedding_service import create_bge_service
from app.services.whisper_service import create_whisper_service
from app.services.clip_service import create_clip_service
from app.services.ollama_service import create_ollama_service
from app.models.ai_model import AIModelModel
from app.core.database import get_db, SessionLocal


class AIModelService:
    """
    AIæ¨¡å‹ç®¡ç†æœåŠ¡

    è´Ÿè´£AIæ¨¡å‹çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€é…ç½®ç®¡ç†å’Œè°ƒç”¨åè°ƒ
    """

    def __init__(self):
        """åˆå§‹åŒ–AIæ¨¡å‹ç®¡ç†æœåŠ¡"""
        self.model_manager = ModelManager()
        self.model_configs: Dict[str, Dict[str, Any]] = {}
        self.default_models: Dict[str, str] = {}  # model_type -> model_id

        logger.info("AIæ¨¡å‹ç®¡ç†æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    async def initialize(self):
        """
        åˆå§‹åŒ–AIæ¨¡å‹ç®¡ç†æœåŠ¡
        ä»æ•°æ®åº“åŠ è½½æ¨¡å‹é…ç½®å¹¶åˆ›å»ºæ¨¡å‹å®ä¾‹
        """
        try:
            logger.info("å¼€å§‹åˆå§‹åŒ–AIæ¨¡å‹ç®¡ç†æœåŠ¡")

            # ä»æ•°æ®åº“åŠ è½½æ¨¡å‹é…ç½®
            await self._load_model_configs_from_db()

            # åˆ›å»ºé»˜è®¤æ¨¡å‹å®ä¾‹
            await self._create_default_models()

            logger.info("AIæ¨¡å‹ç®¡ç†æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            logger.error(f"AIæ¨¡å‹ç®¡ç†æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise

    async def _load_model_configs_from_db(self):
        """ä»æ•°æ®åº“åŠ è½½æ¨¡å‹é…ç½®"""
        try:
            # åˆ›å»ºæ•°æ®åº“ä¼šè¯
            db = SessionLocal()
            try:
                # é¦–å…ˆæ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦æœ‰æ¨¡å‹é…ç½®
                total_models = db.query(AIModelModel).count()

                # å¦‚æœæ²¡æœ‰æ¨¡å‹é…ç½®ï¼Œå…ˆåˆå§‹åŒ–é»˜è®¤é…ç½®
                if total_models == 0:
                    logger.info("æ•°æ®åº“ä¸­æ²¡æœ‰AIæ¨¡å‹é…ç½®ï¼Œåˆå§‹åŒ–é»˜è®¤é…ç½®")
                    await self._initialize_default_configs_to_db(db)

                # æŸ¥è¯¢æ‰€æœ‰æ´»è·ƒçš„æ¨¡å‹é…ç½®
                model_configs = db.query(AIModelModel).filter(AIModelModel.is_active == True).all()

                for config in model_configs:
                    model_id = f"{config.provider}_{config.model_type}_{config.id}"
                    self.model_configs[model_id] = {
                        "id": config.id,
                        "model_type": config.model_type,
                        "provider": config.provider,
                        "model_name": config.model_name,
                        "config": config.config_json
                    }

                logger.info(f"ä»æ•°æ®åº“åŠ è½½äº† {len(self.model_configs)} ä¸ªæ¨¡å‹é…ç½®")

            finally:
                db.close()

        except Exception as e:
            logger.error(f"ä»æ•°æ®åº“åŠ è½½æ¨¡å‹é…ç½®å¤±è´¥: {str(e)}")

    async def _initialize_default_configs_to_db(self, db):
        """
        å°†é»˜è®¤æ¨¡å‹é…ç½®åˆå§‹åŒ–åˆ°æ•°æ®åº“

        Args:
            db: æ•°æ®åº“ä¼šè¯
        """
        try:
            import json
            from app.models.ai_model import AIModelModel

            logger.info("å¼€å§‹å°†é»˜è®¤AIæ¨¡å‹é…ç½®åˆå§‹åŒ–åˆ°æ•°æ®åº“")

            # è·å–é»˜è®¤é…ç½®
            default_configs = AIModelModel.get_default_configs()

            # åˆ›å»ºé»˜è®¤æ¨¡å‹é…ç½®è®°å½•
            created_count = 0

            for config_key, config_data in default_configs.items():
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„é…ç½®
                existing_model = db.query(AIModelModel).filter(
                    AIModelModel.model_type == config_data["model_type"],
                    AIModelModel.provider == config_data["provider"],
                    AIModelModel.model_name == config_data["model_name"]
                ).first()

                if not existing_model:
                    # åˆ›å»ºæ–°çš„æ¨¡å‹é…ç½®
                    new_model = AIModelModel(
                        model_type=config_data["model_type"],
                        provider=config_data["provider"],
                        model_name=config_data["model_name"],
                        config_json=json.dumps(config_data["config"], ensure_ascii=False),
                        is_active=True
                    )
                    db.add(new_model)
                    created_count += 1
                    logger.info(f"åˆ›å»ºé»˜è®¤AIæ¨¡å‹é…ç½®: {config_data['model_type']} - {config_data['model_name']}")
                else:
                    logger.info(f"AIæ¨¡å‹é…ç½®å·²å­˜åœ¨ï¼Œè·³è¿‡: {config_data['model_type']} - {config_data['model_name']}")

            # æäº¤æ‰€æœ‰æ›´æ”¹
            db.commit()

            if created_count > 0:
                logger.info(f"æˆåŠŸåˆå§‹åŒ– {created_count} ä¸ªé»˜è®¤AIæ¨¡å‹é…ç½®åˆ°æ•°æ®åº“")
            else:
                logger.info("æ‰€æœ‰é»˜è®¤AIæ¨¡å‹é…ç½®éƒ½å·²å­˜åœ¨äºæ•°æ®åº“ä¸­")

        except Exception as e:
            logger.error(f"åˆå§‹åŒ–é»˜è®¤AIæ¨¡å‹é…ç½®åˆ°æ•°æ®åº“å¤±è´¥: {str(e)}")
            db.rollback()
            raise

    async def _create_default_models(self):
        """åˆ›å»ºé»˜è®¤æ¨¡å‹å®ä¾‹"""
        try:
            # ä»æ•°æ®åº“é…ç½®åŠ¨æ€åˆ›å»ºæ¨¡å‹å®ä¾‹
            for model_id, model_config in self.model_configs.items():
                model_type = model_config["model_type"]
                provider = model_config.get("provider", "local")
                config = model_config["config"]

                # å¦‚æœconfigæ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦è§£æJSON
                if isinstance(config, str):
                    import json
                    config = json.loads(config)

                # æ ¡éªŒæœ¬åœ°æ¨¡å‹è·¯å¾„
                if provider == "local" and model_type in ["embedding", "speech", "vision"]:
                    await self._validate_and_fix_model_path(model_type, config, model_id)

                try:
                    if model_type == "embedding":
                        # åˆ›å»ºæ–‡æœ¬åµŒå…¥æ¨¡å‹
                        bge_service = create_bge_service(config)
                        self.model_manager.register_model(model_id, bge_service)
                        self.default_models["embedding"] = model_id
                        # ç«‹å³åŠ è½½æ¨¡å‹
                        await self.model_manager.load_model(model_id)
                        logger.info(f"åˆ›å»ºå¹¶åŠ è½½embeddingæ¨¡å‹: {model_id}")

                    elif model_type == "speech":
                        # åˆ›å»ºè¯­éŸ³è¯†åˆ«æ¨¡å‹
                        whisper_service = create_whisper_service(config)
                        self.model_manager.register_model(model_id, whisper_service)
                        self.default_models["speech"] = model_id
                        # ç«‹å³åŠ è½½æ¨¡å‹
                        await self.model_manager.load_model(model_id)
                        logger.info(f"åˆ›å»ºå¹¶åŠ è½½speechæ¨¡å‹: {model_id}")

                    elif model_type == "vision":
                        # åˆ›å»ºå›¾åƒç†è§£æ¨¡å‹
                        clip_service = create_clip_service(config)
                        self.model_manager.register_model(model_id, clip_service)
                        self.default_models["vision"] = model_id
                        # ç«‹å³åŠ è½½æ¨¡å‹
                        await self.model_manager.load_model(model_id)
                        logger.info(f"åˆ›å»ºå¹¶åŠ è½½visionæ¨¡å‹: {model_id}")

                    elif model_type == "llm":
                        # åˆ›å»ºå¤§è¯­è¨€æ¨¡å‹
                        ollama_service = create_ollama_service(config)
                        self.model_manager.register_model(model_id, ollama_service)
                        self.default_models["llm"] = model_id
                        # ç«‹å³åŠ è½½æ¨¡å‹
                        await self.model_manager.load_model(model_id)
                        logger.info(f"åˆ›å»ºå¹¶åŠ è½½llmæ¨¡å‹: {model_id}")

                except Exception as model_error:
                    logger.warning(f"åˆ›å»º{model_type}æ¨¡å‹å¤±è´¥ ({model_id}): {str(model_error)}")

            logger.info(f"åˆ›å»ºäº† {len(self.model_manager.models)} ä¸ªé»˜è®¤æ¨¡å‹å®ä¾‹")

        except Exception as e:
            logger.error(f"åˆ›å»ºé»˜è®¤æ¨¡å‹å®ä¾‹å¤±è´¥: {str(e)}")

    async def load_model(self, model_id: str) -> bool:
        """
        åŠ è½½æŒ‡å®šæ¨¡å‹

        Args:
            model_id: æ¨¡å‹ID

        Returns:
            bool: åŠ è½½æ˜¯å¦æˆåŠŸ
        """
        return await self.model_manager.load_model(model_id)

    async def unload_model(self, model_id: str) -> bool:
        """
        å¸è½½æŒ‡å®šæ¨¡å‹

        Args:
            model_id: æ¨¡å‹ID

        Returns:
            bool: å¸è½½æ˜¯å¦æˆåŠŸ
        """
        return await self.model_manager.unload_model(model_id)

    async def get_model(self, model_type: Union[str, ModelType]) -> Optional[BaseAIModel]:
        """
        æ ¹æ®ç±»å‹è·å–é»˜è®¤æ¨¡å‹

        Args:
            model_type: æ¨¡å‹ç±»å‹

        Returns:
            Optional[BaseAIModel]: æ¨¡å‹å®ä¾‹
        """
        if isinstance(model_type, str):
            model_type = ModelType(model_type)

        # è®°å½•è°ƒè¯•ä¿¡æ¯
        model_type_str = get_enum_value(model_type)
        logger.debug(f"è·å–æ¨¡å‹ç±»å‹: {model_type_str}")
        logger.debug(f"å½“å‰é»˜è®¤æ¨¡å‹æ˜ å°„: {self.default_models}")

        model_id = self.default_models.get(model_type_str)
        logger.debug(f"æ‰¾åˆ°æ¨¡å‹ID: {model_id}")

        if model_id:
            model = self.model_manager.get_model(model_id)
            logger.debug(f"è·å–åˆ°æ¨¡å‹: {model}")
            return model

        logger.warning(f"æœªæ‰¾åˆ°æ¨¡å‹ç±»å‹ {model_type_str} çš„é»˜è®¤æ¨¡å‹")
        return None

    async def text_embedding(self, texts: Union[str, List[str]], **kwargs) -> Any:
        """
        æ–‡æœ¬åµŒå…¥

        Args:
            texts: æ–‡æœ¬æˆ–æ–‡æœ¬åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            Any: åµŒå…¥å‘é‡
        """
        model = await self.get_model(ModelType.EMBEDDING)
        if not model:
            raise AIModelException("æ–‡æœ¬åµŒå…¥æ¨¡å‹ä¸å¯ç”¨")

        return await model.predict(texts, **kwargs)

    async def batch_text_embedding(self, texts: List[str], batch_size: int = 32, **kwargs) -> List[List[float]]:
        """
        æ‰¹é‡æ–‡æœ¬åµŒå…¥

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            List[List[float]]: åµŒå…¥å‘é‡åˆ—è¡¨
        """
        if isinstance(texts, str):
            texts = [texts]

        all_embeddings = []
        total_texts = len(texts)

        # åˆ†æ‰¹å¤„ç†
        for i in range(0, total_texts, batch_size):
            batch_texts = texts[i:i + batch_size]
            try:
                batch_embeddings = await self.text_embedding(batch_texts, **kwargs)

                # å¤„ç†numpyæ•°ç»„è¿”å›å€¼
                if isinstance(batch_embeddings, np.ndarray):
                    if batch_embeddings.ndim == 2:
                        # æ ‡å‡†æƒ…å†µ: (batch_size, embedding_dim)
                        batch_list = batch_embeddings.tolist()
                        all_embeddings.extend(batch_list)
                    elif batch_embeddings.ndim == 1:
                        # å•ä¸ªå‘é‡: (embedding_dim,)
                        all_embeddings.append(batch_embeddings.tolist())
                    else:
                        # å¤šç»´æ•°ç»„ï¼Œå±•å¹³å¤„ç†
                        flattened = [emb.flatten().tolist() for emb in batch_embeddings]
                        all_embeddings.extend(flattened)
                elif isinstance(batch_embeddings, list):
                    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œéœ€è¦æ£€æŸ¥å…ƒç´ ç±»å‹
                    for emb in batch_embeddings:
                        if isinstance(emb, np.ndarray):
                            if emb.ndim > 1:
                                all_embeddings.append(emb.flatten().tolist())
                            else:
                                all_embeddings.append(emb.tolist())
                        else:
                            all_embeddings.append(emb)
                else:
                    # å…¶ä»–ç±»å‹ï¼Œç›´æ¥æ·»åŠ 
                    all_embeddings.append(batch_embeddings)

            except Exception as e:
                logger.error(f"æ‰¹é‡åµŒå…¥å¤„ç†å¤±è´¥ (æ‰¹æ¬¡ {i//batch_size + 1}): {str(e)}")
                # ä½¿ç”¨é›¶å‘é‡ä½œä¸ºfallback
                dummy_embedding = [0.0] * 1024  # BGE-M3æ ‡å‡†ç»´åº¦
                for _ in batch_texts:
                    all_embeddings.append(dummy_embedding)

        return all_embeddings

    async def speech_to_text(self, audio_input: Any, **kwargs) -> Dict[str, Any]:
        """
        è¯­éŸ³è½¬æ–‡å­—

        Args:
            audio_input: éŸ³é¢‘è¾“å…¥
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            Dict[str, Any]: è½¬å½•ç»“æœ
        """
        model = await self.get_model(ModelType.SPEECH)
        if not model:
            raise AIModelException("è¯­éŸ³è¯†åˆ«æ¨¡å‹ä¸å¯ç”¨")

        return await model.predict(audio_input, **kwargs)

    async def image_understanding(self, image_input: Any, texts: List[str], **kwargs) -> Dict[str, Any]:
        """
        å›¾åƒç†è§£

        Args:
            image_input: å›¾åƒè¾“å…¥
            texts: æ–‡æœ¬åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            Dict[str, Any]: ç†è§£ç»“æœ
        """
        model = await self.get_model(ModelType.VISION)
        if not model:
            raise AIModelException("å›¾åƒç†è§£æ¨¡å‹ä¸å¯ç”¨")

        return await model.predict(image_input, texts, **kwargs)

    async def encode_image(self, image_input: Any) -> Any:
        """
        å›¾åƒç¼–ç ä¸ºç‰¹å¾å‘é‡

        Args:
            image_input: å›¾åƒè¾“å…¥

        Returns:
            Any: å›¾åƒç‰¹å¾å‘é‡
        """
        model = await self.get_model(ModelType.VISION)
        if not model:
            raise AIModelException("å›¾åƒç†è§£æ¨¡å‹ä¸å¯ç”¨")

        return await model.encode_image(image_input)

    async def text_generation(self, messages: Union[str, List[Dict]], **kwargs) -> Dict[str, Any]:
        """
        æ–‡æœ¬ç”Ÿæˆ

        Args:
            messages: è¾“å…¥æ¶ˆæ¯
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            Dict[str, Any]: ç”Ÿæˆç»“æœ
        """
        model = await self.get_model(ModelType.LLM)
        if not model:
            raise AIModelException("å¤§è¯­è¨€æ¨¡å‹ä¸å¯ç”¨")

        return await model.predict(messages, **kwargs)

    async def multimodal_search(self, query: str, input_type: str = "text", **kwargs) -> Dict[str, Any]:
        """
        å¤šæ¨¡æ€æœç´¢

        Args:
            query: æœç´¢æŸ¥è¯¢
            input_type: è¾“å…¥ç±»å‹ (text/speech/image)
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            Dict[str, Any]: æœç´¢ç»“æœ
        """
        try:
            results = {
                "query": query,
                "input_type": input_type,
                "processing_time": 0,
                "results": [],
                "error": None
            }

            start_time = datetime.now()

            # æ ¹æ®è¾“å…¥ç±»å‹å¤„ç†æŸ¥è¯¢
            if input_type == "speech":
                # è¯­éŸ³è½¬æ–‡å­—
                transcription_result = await self.speech_to_text(query, **kwargs)
                processed_query = transcription_result.get("text", "")
                results["transcription"] = transcription_result
            elif input_type == "image":
                # å›¾åƒç†è§£ç”Ÿæˆæœç´¢æŸ¥è¯¢
                if "texts" not in kwargs:
                    kwargs["texts"] = ["æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹", "è¿™å¼ å›¾ç‰‡å±•ç¤ºäº†ä»€ä¹ˆ"]
                vision_result = await self.image_understanding(query, **kwargs)
                processed_query = vision_result.get("best_match", {}).get("text", "")
                results["vision_understanding"] = vision_result
            else:
                # æ–‡æœ¬æŸ¥è¯¢ç›´æ¥ä½¿ç”¨
                processed_query = query

            if not processed_query:
                raise AIModelException("æ— æ³•å¤„ç†æœç´¢æŸ¥è¯¢")

            # ä½¿ç”¨æ–‡æœ¬åµŒå…¥è¿›è¡Œè¯­ä¹‰æœç´¢
            embedding_result = await self.text_embedding(processed_query)
            results["embedding"] = embedding_result

            # ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ä¼˜åŒ–æŸ¥è¯¢ï¼ˆå¯é€‰ï¼‰
            if kwargs.get("use_llm_query_expansion", False):
                expansion_result = await self.text_generation([
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœç´¢åŠ©æ‰‹ï¼Œè¯·å¸®ç”¨æˆ·ä¼˜åŒ–æœç´¢æŸ¥è¯¢ï¼Œæä¾›æ›´å…·ä½“çš„æœç´¢å…³é”®è¯ã€‚"},
                    {"role": "user", "content": f"è¯·ä¸ºä»¥ä¸‹æœç´¢æŸ¥è¯¢æä¾›æ›´å¥½çš„å…³é”®è¯ï¼š{processed_query}"}
                ])
                results["query_expansion"] = expansion_result

            results["processed_query"] = processed_query
            results["processing_time"] = (datetime.now() - start_time).total_seconds()

            return results

        except Exception as e:
            logger.error(f"å¤šæ¨¡æ€æœç´¢å¤±è´¥: {str(e)}")
            return {
                "query": query,
                "input_type": input_type,
                "processing_time": 0,
                "results": [],
                "error": str(e)
            }

    async def get_model_status(self) -> Dict[str, Any]:
        """
        è·å–æ‰€æœ‰æ¨¡å‹çŠ¶æ€

        Returns:
            Dict[str, Any]: æ¨¡å‹çŠ¶æ€ä¿¡æ¯
        """
        return self.model_manager.get_status_summary()

    async def health_check(self) -> Dict[str, bool]:
        """
        å¥åº·æ£€æŸ¥æ‰€æœ‰æ¨¡å‹

        Returns:
            Dict[str, bool]: æ¯ä¸ªæ¨¡å‹çš„å¥åº·çŠ¶æ€
        """
        return await self.model_manager.health_check_all()

    async def load_all_models(self) -> Dict[str, bool]:
        """
        åŠ è½½æ‰€æœ‰æ¨¡å‹

        Returns:
            Dict[str, bool]: æ¯ä¸ªæ¨¡å‹çš„åŠ è½½ç»“æœ
        """
        return await self.model_manager.load_all_models()

    async def unload_all_models(self) -> Dict[str, bool]:
        """
        å¸è½½æ‰€æœ‰æ¨¡å‹

        Returns:
            Dict[str, bool]: æ¯ä¸ªæ¨¡å‹çš„å¸è½½ç»“æœ
        """
        return await self.model_manager.unload_all_models()

    async def register_model(self, model_id: str, model_config: Dict[str, Any]) -> bool:
        """
        æ³¨å†Œæ–°æ¨¡å‹

        Args:
            model_id: æ¨¡å‹ID
            model_config: æ¨¡å‹é…ç½®

        Returns:
            bool: æ³¨å†Œæ˜¯å¦æˆåŠŸ
        """
        try:
            model_type = model_config.get("model_type")
            provider = model_config.get("provider")
            config = model_config.get("config", {})

            # æ ¹æ®ç±»å‹åˆ›å»ºæ¨¡å‹å®ä¾‹
            if model_type == "embedding":
                model = create_bge_service(config)
            elif model_type == "speech":
                model = create_whisper_service(config)
            elif model_type == "vision":
                model = create_clip_service(config)
            elif model_type == "llm":
                model = create_ollama_service(config)
            else:
                raise AIModelException(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")

            # æ³¨å†Œæ¨¡å‹
            self.model_manager.register_model(model_id, model)
            self.model_configs[model_id] = model_config

            logger.info(f"æˆåŠŸæ³¨å†Œæ¨¡å‹: {model_id}")
            return True

        except Exception as e:
            logger.error(f"æ³¨å†Œæ¨¡å‹å¤±è´¥: {model_id}, é”™è¯¯: {str(e)}")
            return False

    async def unregister_model(self, model_id: str) -> bool:
        """
        æ³¨é”€æ¨¡å‹

        Args:
            model_id: æ¨¡å‹ID

        Returns:
            bool: æ³¨é”€æ˜¯å¦æˆåŠŸ
        """
        try:
            # å…ˆå¸è½½æ¨¡å‹
            await self.unload_model(model_id)

            # æ³¨é”€æ¨¡å‹
            self.model_manager.unregister_model(model_id)
            self.model_configs.pop(model_id, None)

            # ç§»é™¤é»˜è®¤æ¨¡å‹æ˜ å°„
            for model_type, default_id in self.default_models.items():
                if default_id == model_id:
                    del self.default_models[model_type]
                    break

            logger.info(f"æˆåŠŸæ³¨é”€æ¨¡å‹: {model_id}")
            return True

        except Exception as e:
            logger.error(f"æ³¨é”€æ¨¡å‹å¤±è´¥: {model_id}, é”™è¯¯: {str(e)}")
            return False

    async def set_default_model(self, model_type: str, model_id: str) -> bool:
        """
        è®¾ç½®é»˜è®¤æ¨¡å‹

        Args:
            model_type: æ¨¡å‹ç±»å‹
            model_id: æ¨¡å‹ID

        Returns:
            bool: è®¾ç½®æ˜¯å¦æˆåŠŸ
        """
        if model_id not in self.model_manager.models:
            logger.error(f"æ¨¡å‹ä¸å­˜åœ¨: {model_id}")
            return False

        self.default_models[model_type] = model_id
        logger.info(f"è®¾ç½®é»˜è®¤æ¨¡å‹: {model_type} -> {model_id}")
        return True

    async def get_available_models(self) -> Dict[str, List[Dict[str, Any]]]:
        """
        è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨

        Returns:
            Dict[str, List[Dict[str, Any]]]: æŒ‰ç±»å‹åˆ†ç»„çš„æ¨¡å‹åˆ—è¡¨
        """
        models_by_type = {}
        for model_type in ModelType:
            models_by_type[get_enum_value(model_type)] = []

        for model_id, model in self.model_manager.models.items():
            model_info = {
                "model_id": model_id,
                "model_name": model.model_name,
                "model_type": get_enum_value(model.model_type),
                "provider": get_enum_value(model.provider),
                "status": get_enum_value(model.status),
                "is_default": self.default_models.get(get_enum_value(model.model_type)) == model_id,
                "config": model.get_model_info()
            }
            models_by_type[get_enum_value(model.model_type)].append(model_info)

        return models_by_type

    async def benchmark_models(self, model_types: List[str] = None) -> Dict[str, Any]:
        """
        æ€§èƒ½åŸºå‡†æµ‹è¯•

        Args:
            model_types: è¦æµ‹è¯•çš„æ¨¡å‹ç±»å‹åˆ—è¡¨

        Returns:
            Dict[str, Any]: æ€§èƒ½æµ‹è¯•ç»“æœ
        """
        results = {}

        for model_id, model in self.model_manager.models.items():
            if model_types and get_enum_value(model.model_type) not in model_types:
                continue

            try:
                if model.model_type == ModelType.EMBEDDING:
                    # BGE-M3æ€§èƒ½æµ‹è¯•
                    test_texts = ["è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬", "å¦ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"]
                    benchmark_result = await model.benchmark_performance(test_texts)
                elif model.model_type == ModelType.SPEECH:
                    # Whisperæ€§èƒ½æµ‹è¯•
                    test_files = []  # éœ€è¦æä¾›æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
                    benchmark_result = {"message": "è¯­éŸ³æ¨¡å‹æ€§èƒ½æµ‹è¯•éœ€è¦æµ‹è¯•éŸ³é¢‘æ–‡ä»¶"}
                elif model.model_type == ModelType.VISION:
                    # CLIPæ€§èƒ½æµ‹è¯•
                    test_images = []  # éœ€è¦æä¾›æµ‹è¯•å›¾ç‰‡
                    benchmark_result = {"message": "è§†è§‰æ¨¡å‹æ€§èƒ½æµ‹è¯•éœ€è¦æµ‹è¯•å›¾ç‰‡"}
                elif model.model_type == ModelType.LLM:
                    # Ollamaæ€§èƒ½æµ‹è¯•
                    test_messages = ["ä½ å¥½", "è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±"]
                    benchmark_result = await model.benchmark_performance(test_messages)
                else:
                    benchmark_result = {"message": "ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹"}

                results[model_id] = benchmark_result

            except Exception as e:
                logger.error(f"æ¨¡å‹ {model_id} æ€§èƒ½æµ‹è¯•å¤±è´¥: {str(e)}")
                results[model_id] = {"error": str(e)}

        return results

    async def reload_model(self, model_type: str) -> Dict[str, Any]:
        """
        çƒ­é‡è½½æŒ‡å®šç±»å‹çš„æ¨¡å‹

        Args:
            model_type: æ¨¡å‹ç±»å‹ (embedding/speech/vision/llm)

        Returns:
            Dict[str, Any]: é‡è½½ç»“æœ
        """
        import time
        start_time = time.time()

        try:
            logger.info(f"å¼€å§‹çƒ­é‡è½½æ¨¡å‹: {model_type}")

            # æŸ¥æ‰¾å½“å‰é»˜è®¤æ¨¡å‹
            current_model_id = self.default_models.get(model_type)
            if not current_model_id:
                return {
                    "success": False,
                    "message": f"æœªæ‰¾åˆ°{model_type}ç±»å‹çš„é»˜è®¤æ¨¡å‹",
                    "reload_time": 0
                }

            # å¸è½½å½“å‰æ¨¡å‹
            logger.info(f"å¸è½½å½“å‰æ¨¡å‹: {current_model_id}")
            unload_success = await self.unload_model(current_model_id)
            if not unload_success:
                return {
                    "success": False,
                    "message": f"å¸è½½æ¨¡å‹å¤±è´¥: {current_model_id}",
                    "reload_time": 0
                }

            # ä»æ•°æ®åº“é‡æ–°åŠ è½½é…ç½®
            await self._load_model_configs_from_db()

            # æŸ¥æ‰¾æ–°çš„æ¨¡å‹é…ç½®
            new_model_id = None
            new_model_config = None

            for model_id, config in self.model_configs.items():
                if config.get("model_type") == model_type and config.get("is_active", True):
                    # é€‰æ‹©æœ€æ–°çš„é…ç½®
                    if not new_model_config or config.get("id", 0) > new_model_config.get("id", 0):
                        new_model_id = model_id
                        new_model_config = config

            if not new_model_id or not new_model_config:
                return {
                    "success": False,
                    "message": f"æœªæ‰¾åˆ°{model_type}ç±»å‹çš„æœ‰æ•ˆé…ç½®",
                    "reload_time": time.time() - start_time
                }

            # åˆ›å»ºå¹¶åŠ è½½æ–°æ¨¡å‹
            logger.info(f"åˆ›å»ºå¹¶åŠ è½½æ–°æ¨¡å‹: {new_model_id}")
            config = new_model_config.get("config", {})
            if isinstance(config, str):
                import json
                config = json.loads(config)

            # æ ¹æ®æ¨¡å‹ç±»å‹åˆ›å»ºæ–°æ¨¡å‹å®ä¾‹
            new_model = None
            if model_type == "embedding":
                new_model = create_bge_service(config)
            elif model_type == "speech":
                new_model = create_whisper_service(config)
            elif model_type == "vision":
                new_model = create_clip_service(config)
            elif model_type == "llm":
                new_model = create_ollama_service(config)
            else:
                return {
                    "success": False,
                    "message": f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}",
                    "reload_time": time.time() - start_time
                }

            # æ³¨å†Œæ–°æ¨¡å‹
            self.model_manager.register_model(new_model_id, new_model)

            # åŠ è½½æ–°æ¨¡å‹
            load_success = await self.model_manager.load_model(new_model_id)
            if not load_success:
                return {
                    "success": False,
                    "message": f"åŠ è½½æ–°æ¨¡å‹å¤±è´¥: {new_model_id}",
                    "reload_time": time.time() - start_time
                }

            # æ›´æ–°é»˜è®¤æ¨¡å‹æ˜ å°„
            self.default_models[model_type] = new_model_id

            reload_time = time.time() - start_time
            logger.info(f"æ¨¡å‹çƒ­é‡è½½æˆåŠŸ: {model_type} -> {new_model_id}, è€—æ—¶: {reload_time:.3f}ç§’")

            return {
                "success": True,
                "message": f"{model_type}æ¨¡å‹çƒ­é‡è½½æˆåŠŸ",
                "reload_time": round(reload_time, 3),
                "old_model_id": current_model_id,
                "new_model_id": new_model_id
            }

        except Exception as e:
            logger.error(f"æ¨¡å‹çƒ­é‡è½½å¤±è´¥: {model_type}, é”™è¯¯: {str(e)}")
            return {
                "success": False,
                "message": f"æ¨¡å‹çƒ­é‡è½½å¤±è´¥: {str(e)}",
                "reload_time": time.time() - start_time
            }

    async def reload_all_models(self) -> Dict[str, Any]:
        """
        çƒ­é‡è½½æ‰€æœ‰æ¨¡å‹

        Returns:
            Dict[str, Any]: é‡è½½ç»“æœ
        """
        results = {}

        for model_type in ["embedding", "speech", "vision", "llm"]:
            results[model_type] = await self.reload_model(model_type)

        return results

    async def _validate_and_fix_model_path(self, model_type: str, config: dict, model_id: str):
        """
        æ ¡éªŒå¹¶ä¿®å¤æ¨¡å‹è·¯å¾„é…ç½®

        Args:
            model_type: æ¨¡å‹ç±»å‹ (embedding/speech/vision)
            config: æ¨¡å‹é…ç½®å­—å…¸
            model_id: æ¨¡å‹ID
        """
        import os

        model_path = config.get("model_path")
        model_name = config.get("model_name")

        if not model_path:
            logger.info(f"{model_type}æ¨¡å‹é…ç½®ä¸­æ²¡æœ‰model_pathï¼Œå°†ä½¿ç”¨ç½‘ç»œæ¨¡å‹: {model_name}")
            return

        # æ£€æŸ¥æœ¬åœ°è·¯å¾„æ˜¯å¦å­˜åœ¨
        if os.path.exists(model_path):
            logger.info(f"âœ… {model_type}æœ¬åœ°æ¨¡å‹è·¯å¾„å­˜åœ¨: {model_path}")
            # éªŒè¯æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§
            await self._verify_model_files(model_type, model_path, model_id)
        else:
            logger.warning(f"âš ï¸ {model_type}æœ¬åœ°æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
            logger.warning(f"ğŸ“ å°è¯•åˆ›å»ºçˆ¶ç›®å½•: {os.path.dirname(model_path)}")

            # å°è¯•åˆ›å»ºçˆ¶ç›®å½•
            parent_dir = os.path.dirname(model_path)
            try:
                os.makedirs(parent_dir, exist_ok=True)
                logger.info(f"âœ… æˆåŠŸåˆ›å»ºæ¨¡å‹ç›®å½•: {parent_dir}")
            except PermissionError:
                logger.error(f"âŒ æ²¡æœ‰æƒé™åˆ›å»ºç›®å½•: {parent_dir}")
            except Exception as e:
                logger.error(f"âŒ åˆ›å»ºç›®å½•å¤±è´¥: {parent_dir}, é”™è¯¯: {str(e)}")

    async def _verify_model_files(self, model_type: str, model_path: str, model_id: str):
        """
        éªŒè¯æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§

        Args:
            model_type: æ¨¡å‹ç±»å‹
            model_path: æ¨¡å‹è·¯å¾„
            model_id: æ¨¡å‹ID
        """
        import os

        try:
            if os.path.isfile(model_path):
                # å•æ–‡ä»¶æ¨¡å‹
                file_size = os.path.getsize(model_path)
                logger.info(f"ğŸ“„ {model_type}æ¨¡å‹æ–‡ä»¶: {model_path}, å¤§å°: {file_size / (1024*1024):.1f}MB")
            elif os.path.isdir(model_path):
                # ç›®å½•æ¨¡å‹ï¼Œæ£€æŸ¥å…³é”®æ–‡ä»¶
                files = os.listdir(model_path)
                logger.info(f"ğŸ“ {model_type}æ¨¡å‹ç›®å½•: {model_path}, æ–‡ä»¶æ•°é‡: {len(files)}")

                # æ ¹æ®æ¨¡å‹ç±»å‹æ£€æŸ¥å¿…éœ€æ–‡ä»¶
                required_files = self._get_required_model_files(model_type)
                missing_files = []

                for file_pattern in required_files:
                    found = any(file_pattern.replace('*', '') in f for f in files)
                    if not found:
                        missing_files.append(file_pattern)

                if missing_files:
                    logger.warning(f"âš ï¸ {model_type}æ¨¡å‹å¯èƒ½ç¼ºå°‘å¿…è¦æ–‡ä»¶: {missing_files}")
                else:
                    logger.info(f"âœ… {model_type}æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")

        except Exception as e:
            logger.error(f"âŒ éªŒè¯{model_type}æ¨¡å‹æ–‡ä»¶å¤±è´¥: {str(e)}")

    def _get_required_model_files(self, model_type: str) -> list:
        """
        è·å–å„ç±»å‹æ¨¡å‹çš„å¿…éœ€æ–‡ä»¶åˆ—è¡¨

        Args:
            model_type: æ¨¡å‹ç±»å‹

        Returns:
            list: å¿…éœ€æ–‡ä»¶æ¨¡å¼åˆ—è¡¨
        """
        if model_type == "embedding":
            return ["config.json", "pytorch_model.bin"]
        elif model_type == "speech":
            return ["model.bin"]
        elif model_type == "vision":
            return ["config.json", "pytorch_model.bin"]
        else:
            return []

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        await self.initialize()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        await self.unload_all_models()


# å…¨å±€AIæ¨¡å‹æœåŠ¡å®ä¾‹
ai_model_service = AIModelService()